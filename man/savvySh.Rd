% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/savvySh.main.R
\name{savvySh}
\alias{savvySh}
\title{Slab and Shrinkage Linear Regression Estimation}
\usage{
savvySh(x, y, model_class = c("Multiplicative", "Slab", "Linear", "ShrinkageRR"),
               v = 1, lambda_vals = NULL, nlambda = 100, folds = 10,
               foldid = FALSE, include_Sh = FALSE, exclude = NULL)
}
\arguments{
\item{x}{A matrix of predictor variables.}

\item{y}{A vector of response variable.}

\item{model_class}{A character string specifying the shrinkage model to use. Options are \code{"Multiplicative"},
\code{"Slab"}, \code{"Linear"}, and \code{"ShrinkageRR"}. The default is \code{"Multiplicative"}.}

\item{v}{A numeric value controlling the strength of shrinkage for the SR estimator in the Slab model.
Must be a positive number.}

\item{lambda_vals}{A vector of \code{lambda} values for Ridge Regression. This is used only when
multicollinearity (rank deficiency) is detected and \code{"ShrinkageRR"} is not selected.
If \code{NULL}, a default sequence is used.}

\item{nlambda}{The number of \code{lambda} values to use for cross-validation if \code{lambda_vals} is \code{NULL}.
Only used when multicollinearity is present and \code{"ShrinkageRR"} is not called. The default is \code{100}.}

\item{folds}{Number of folds for cross-validation in Ridge Regression. This is applicable only if multicollinearity occurs
and \code{"ShrinkageRR"} is not chosen. The default is \code{10} and must be an integer \code{>= 3}.}

\item{foldid}{Logical. If \code{TRUE}, saves the fold assignments in the output when multicollinearity is detected
and \code{"ShrinkageRR"} is not used. The default is \code{FALSE}.}

\item{include_Sh}{Logical. If \code{TRUE}, includes the Sh estimator in the \code{"Multiplicative"} model.}

\item{exclude}{A vector specifying columns to exclude from the predictors.}
}
\value{
A list containing the following elements:
\item{call}{The matched function call.}
\item{model}{The data frame of \code{y} and \code{x} used in the analysis.}
\item{optimal_lambda}{The \code{lambda} value chosen in \code{RR} if \code{x} is not full rank.}
\item{model_class}{The selected model class.}
\item{coefficients}{A list of estimated coefficients for each applicable estimator in the \code{model_class}.}
\item{fitted_values}{A list of fitted values for each estimator.}
\item{pred_MSE}{A list of prediction \code{MSE}s for each estimator.}
\item{ridge_results (optional)}{
 A list containing detailed results from \code{RR}, used when multicollinearity (rank deficiency)
 is detected in \code{x} and the \code{"ShrinkageRR"} is not called. This element is included only when \code{RR} is applied instead of \code{OLS}
 due to the rank deficiency of \code{x}. It contains:
 \describe{
 \item{\code{lambda_range}}{The range of \code{lambda} values used in the \code{RR} cross-validation.}
 \item{\code{cvm}}{A vector of cross-validated mean squared errors for each \code{lambda} in \code{lambda_range}.}
 \item{\code{cvsd}}{The standard deviation of the cross-validated mean squared errors for each \code{lambda}.}
 \item{\code{ridge_coefficients}}{A matrix of coefficients from \code{RR} at each \code{lambda} value,
 with each column representing the coefficients corresponding to a specific \code{lambda}.}
 \item{\code{optimal_lambda}}{The \code{lambda} value that minimizes the cross-validated mean squared error,
 which is used for the final \code{RR} estimation when multicollinearity is detected.}
 }
}
}
\description{
This function estimates coefficients in a linear regression model using several shrinkage methods,
including Multiplicative Shrinkage, Slab Regression, Linear shrinkage, and Shrinkage Ridge Regression.
Each method gives estimators that balance bias and variance by applying shrinkage to the ordinary
least squares (OLS) solution. The shrinkage estimators are computed based on different assumptions
about the data.
}
\details{
The \emph{Slab and Shrinkage Linear Regression Estimation} methodology provides a set of estimators that balance bias and variance through shrinkage techniques.
These estimators address issues by incorporating controlled shrinkage on the \code{OLS} solution. The main function offers three classes of shrinkage estimators,
each tailored for different modeling contexts in \code{model_class}.

\strong{Model Classes:}
\describe{
  \item{\strong{Multiplicative Shrinkage:}}{
    This class includes three estimators that use the \code{OLS} coefficients as a starting point and apply \emph{multiplicative} adjustments:
    \describe{
      \item{\code{St - }}{\emph{Stein estimator}, which shrinks all coefficients toward zero to reduce variance while maintaining unbiasedness.}
      \item{\code{DSh - }}{\emph{Diagonal Shrinkage}, where each coefficient is shrunk individually based on its corresponding variance, allowing more targeted shrinkage.}
      \item{\code{Sh - }}{A \emph{Shrinkage estimator} that solves a \emph{Sylvester equation} for optimal shrinkage; it is included only if \code{include_Sh = TRUE}.}
    }
  }

  \item{\strong{Slab Regression:}}{
    \emph{Slab Regression} includes two estimators that apply an adaptive penalty term to the solution:
    \describe{
      \item{\code{SR - }}{\emph{Simple Slab Regression} modifies the OLS objective by incorporating a quadratic penalty in a fixed direction.
      This penalty is controlled by a tuning parameter denoted as \code{v}. This approach can be viewed as a special case of the \code{generalized lasso}
      but it does not require cross-validation for tuning.}
      \item{\code{GSR - }}{\emph{Generalized Slab Regression} extends \code{SR} by allowing shrinkage along multiple directions.
      In this case, the penalty is applied along the eigenvectors of the design covariance matrix, effectively shrinking the estimates
      in a way that targets selected principal components.}
    }
  }

  \item{\strong{Linear Shrinkage:}}{
    The \emph{Linear Shrinkage (LSh)} estimator forms a convex combination of the OLS estimator (through the origin) and a target estimator
    that assumes uncorrelated predictors. This is suitable for standardized data and provides a simple alternative to more complex shrinkage methods.
  }

  \item{\strong{Shrinkage Ridge Regression:}}{
    The \emph{Shrinkage Ridge Regression (SRR)} extends standard ridge regression by additionally shrinking the sample covariance matrix toward a spherical target
    (i.e., a diagonal matrix with equal entries). This extra regularization stabilizes the eigenvalues and yields more robust coefficient estimates,
    particularly when the predictors lie close to a low-dimensional subspace.
  }
}
}
\references{
Asimit, V., Cidota, M. A., Chen, Z., & Asimit, J. (2025). \emph{Slab and Shrinkage Linear Regression Estimation}.
(Manuscript in preparation).
}
\author{
Ziwei Chen, Vali Asimit, Marina Anca Cidota, Jennifer Asimit\cr
Maintainer: Ziwei Chen <ziwei.chen.3@citystgeorges.ac.uk>
}
